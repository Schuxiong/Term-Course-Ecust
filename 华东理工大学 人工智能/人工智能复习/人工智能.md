# 1.绪论

## 一、人工智能的定义

人工智能（Artificial Intelligence，简称AI），是指用机器（计算机）模拟或实现人类的智能。它是计算机科学的一个分支，涉及研究、设计和应用智能机器，使计算机能够像人类一样感知、思考、学习和解决问题。

## 二、图灵测试

1. **提出者**：英国数学家、逻辑学家艾伦·麦席森·图灵（Alan Mathison Turing）。
2. **时间**：1950年。
3. **内容**：图灵测试是一种用于判断机器是否具有智能的方法。在测试中，一个人（A）与一台机器（B）和另一个人（C）进行交互。A通过向B和C提出问题，并根据他们的回答来判断哪个是机器，哪个是人。如果A无法区分B和C，那么就可以认为机器具有智能。
4. **意义**：图灵测试为人工智能的发展提供了一个重要的标准和目标，推动了人工智能的研究和发展。

## 三、三大流派及其主要思想

1. 符号主义（Symbolicism）

   ：

   - **主要思想**：符号主义认为人工智能源于数理逻辑，人类认知的基本元素是符号，认知过程就是符号处理的过程。因此，可以通过编写程序来模拟人类的智能行为。
   - **代表人物**：赫伯特·西蒙（Herbert Alexander Simon）和艾伦·纽厄尔（Allen Newell）。
   - **应用领域**：专家系统、知识工程等。

2. 连接主义（Connectionism）

   ：

   - **主要思想**：连接主义认为人工智能源于仿生学，人类智能的基础是大脑的神经元网络。因此，可以通过构建人工神经网络来模拟人类的智能行为。
   - **代表人物**：杰弗里·辛顿（Geoffrey Hinton）、杨立昆（Yann LeCun）和约书亚·本吉奥（Yoshua Bengio）。
   - **应用领域**：机器学习、计算机视觉、自然语言处理等。

3. 行为主义（Behaviorism）

   ：

   - **主要思想**：行为主义认为人工智能源于控制论，智能取决于感知和行动，人的智能、机器智能可以逐步进化，但只能在现实世界中与周围环境的交互中体现出来。
   - **代表人物**：罗德尼·布鲁克斯（Rodney Brooks）。
   - **应用领域**：机器人、智能控制等。

## 四、AI学科诞生

1. **时间**：1956年。
2. **地点**：美国达特茅斯学院。
3. **发起人**：约翰·麦卡锡（John McCarthy）、马文·明斯基（Marvin Minsky）、克劳德·香农（Claude Shannon）、艾伦·纽厄尔（Allen Newell）和赫伯特·西蒙（Herbert Simon）等。
4. **意义**：这次会议标志着人工智能学科的正式诞生，为人工智能的发展奠定了基础。



# 2.知识表示及确定性推理

命题符号化、命题公式的计算及分类、命题公式的关系，谓词逻辑

传统推理的理论基础、三大组成部分、推理树

## 一、命题符号化

1. **命题**：一个非真即假的陈述句。

2. **命题变量**：一组命题的任意一个，不是命题。

3. **命题常量**：一个具体的命题，可以使用命题标识符表示。

4. 逻辑连接词

   ：

   - **否定**（negation）或“非”（﹁）。

   - **析取**（disjunction）——或（∨）。

   - **合取**（conjunction）——与（∧）。

   - **蕴含**（implication）或“条件”（condition）（→）。

   - **等价**（equivalence）或“双条件”（bicondition）（⟷）。

     ![image-20240702122337188](C:\Users\74140\AppData\Roaming\Typora\typora-user-images\image-20240702122337188.png)

5. 命题符号化步骤

   ：

   - 找出各简单命题，分别符号化。
   - 找出各联结词，把简单命题逐个联结起来。

## 二、命题公式的计算及分类

1. **命题公式**：由有限个命题常量，命题变量，联结词，括号等组成的字符串。

2. **命题公式的真值表**：在所有赋值之下取值列成的表。

3. 命题公式的分类

   ：

   - **重言式**（永真式）：命题公式在任何一组真值指派下的真值都为1。
   - **矛盾式**（永假式）：命题公式在任何一组真值指派下的真值都为0。
   - **可满足式**：命题公式在至少一组真值指派下的真值为1。

## 三、命题公式的关系

1. **等价**：对于两个命题公式，如果是重言式，则称它们是等价的。
2. **蕴含**：对于两个命题公式，如果是重言式，则称蕴含。

## 四、谓词逻辑

1. **谓词**：刻画个体的性质、状态或个体间的关系。

2. **谓词公式**：由有限个谓词常量，谓词变量，联结词，括号等组成的字符串。

3. 量词

   ：

   - **全称量词**（universal quantifier）（x）：“对个体域中的所有（或任一个）个体x”。
   - **存在量词**（existential quantifier）（x）：“在个体域中存在个体x”。

4. 谓词公式的性质

   ：

   - **谓词公式的解释**：个体域中的实体对谓词演算表达式的每个常量、变量、谓词和函数符号的指派。

   - 谓词公式的永真性、可满足性、不可满足性

     ：

     - **永真**：如果谓词公式P对个体域D上的任何一个解释都取得真值T，则称P在D上是永真的；如果P在每个非空个体域上均永真，则称P永真。
     - **可满足**：如果至少存在一个解释使得P在此解释下的真值为T，则称P是可满足的，否则，则称P是不可满足的。
     - **不可满足**：如果谓词公式P对个体域D上的任何一个解释都取得真值F，则称P在D上是永假的；如果P在每个非空个体域上均永假，则称P永假。

   - **谓词公式的等价性**：设P与Q是两个谓词公式，D是它们共同的个体域，若对D上的任何一个解释，P与Q都有相同的真值，则称公式P和Q在D上是等价的。如果D是任意个体域，则称P和Q是等价的，记为P Q。

   - **谓词公式的永真蕴含**：对于谓词公式P与Q，如果P→Q永真，则称公式P永真蕴含Q，且称Q为P的逻辑结论，称P为Q的前提，记为P Q。

## 五、传统推理的理论基础

1. **命题逻辑**：研究命题及命题之间关系的符号逻辑系统。
2. **谓词逻辑**：在命题逻辑的基础上，对命题进行进一步的分析和推理。

## 六、传统推理的三大组成部分

1. **知识库**：包含一系列的规则。
2. **综合数据库**：包含已知的命题。
3. **推理机**：采用链式规则推理。

## 七、推理树

1. **推理树**：是一种用于表示推理过程的树形结构。

2. 节点类型

   ：

   - **与节点**：表示多个条件同时满足。
   - **或节点**：表示多个条件中至少有一个满足。

3. **推理树的构建**：从知识库中取出规则，根据规则的前提和结论，构建推理树。

4. **推理树的遍历**：从根节点开始，按照深度优先或广度优先的方式遍历推理树，直到找到目标节点或遍历完所有节点。



# 3.不确定性推理

可信度及其取值含义、不确定性的传递算法及合成、带加权因子的可信度推理

## 一、可信度及其取值含义

1. **可信度**：表示在证据e出现的前提下，结论h为真的概率变化程度。

2. 取值含义

   ：

   - **大于0**：证据e的出现增加了结论h为真的概率；等于1时，证据e使得h为真。
   - **小于0**：证据e的出现减少了结论h为真的概率；等于-1时，证据e使得h为假。
   - **等于0**：证据e和结论h不相关。

## 二、不确定性的传递算法及合成

1. 不确定性的传递算法

   ：

   - **组合证据为多个证据的合取时**：即E=E1 AND E2 AND … En，CF(E)=min{CF(E1),CF(E2),…,CF(En)}。
   - **组合证据为多个证据的析取时**：即E=E1 OR E2 OR … En，CF(E)=max{CF(E1),CF(E2),…,CF(En)}。

2. 不确定性的合成

   ：

   - 考虑如下两条规则下的推理

     ：

     - **IF E1 THEN H(CF(H,E1))**
     - **IF E2 THEN H(CF(H,E2))**

   - **不同**：IF E1 OR E2 THEN H

   - 利用每一条规则，分别计算

     ：

     - **CF1(H)=CF(H,E1)×CF(E1)**
     - **CF2(H)=CF(H,E2)×CF(E2)**

   - 则两条规则下的结论可信度合成公式

     ：

     - **CF1,2(H)=CF1(H)+CF2(H) - CF1(H)×CF2(H)**
     - **CF1,2,3(H)=CF1,2(H)+CF3(H) / (1-min{ | CF1,2(H)|, |CF3(H)| } )**

## 三、带加权因子的可信度推理

1. **规则不确定性的表示**：IF E1(ω1) AND E2(ω2) AND … En(ωn) THEN H (CF(H,E))，其中，ωi是加权因子，且ω1+ω2+…+ωn=1。

2. **组合证据不确定性算法**：CF(H)=CF(H,E)×CF(E)。

3. 不确定性的更新算法

   ：

   - 例1

     ：设有下列知识：IF 该动物有蹄（0.3）AND 该动物有长腿（0.2）AND 该动物有长颈（0.2）AND 该动物是黄褐色（0.1）AND 该动物身上有暗黑色斑点（0.2）THEN 该动物是长颈鹿（0.8），证据为：E1: 该动物有蹄（1），E2: 该动物有长腿（1），E3: 该动物有长颈（1），E4: 该动物是黄褐色（0.8），E5: 该动物身上有暗黑色斑点（0.6），试画出推理树，并推理出该动物是什么动物？

     - **解**：CF(E)=0.3×1+0.2×1+0.2×1+0.1×0.8+0.2×0.6=0.9，推出该动物是长颈鹿，其可信度为：CF(H)=CF(H,E) ×CF(E)=0.9 ×0.8=0.72。

   - 例2

     ：设有下列规则：r1: IF E1(0.6) AND E2(0.4) THEN E6(0.8)，r2: IF E3(0.5) AND E4 (0.3) AND E5 (0.2) THEN E7 (0.7)，r3: IF E6 (0.7) AND E7(0.3) THEN H(0.75)，已知：CF(E1)=0.9, CF(E2)=0.8, CF(E3)=0.7，CF(E4)=0.6, CF(E5)=0.5，画出推理树，并计算CF(H)。

     - **解**：由r1 有：CF(E1(0.6) AND E2(0.4))=0.6×0.9+0.4×0.8=0.86，由r2 有：CF(E3(0.5) AND E4(0.3) AND E5(0.2))=0.5×0.7+0.3×0.6+0.2×0.5=0.63，由r1 有：CF(E6)=0.8×0.86=0.688，由r2 有：CF(E7)=0.7×0.63=0.441，由r3 有：CF(E)=CF(E6 (0.7) AND E7 (0.3))=0.7×0.688+0.3×0.441=0.6139，CF(H)=CF(H,E)×CF(E)=0.75×0.6139=0.460425。

# 4.模糊推理

模糊集合的表示及其各种运算，贴近度，模糊推理及模糊决策的计算

## 一、模糊数学基础

1. 模糊集合

   ：

   - **定义**：设U是论域，称映射A(x)：U→[0,1]确定了一个U上的模糊子集A，映射A(x)称为A的隶属函数，它表示x对A的隶属程度。

   - 表示

     ：

     - **形式1**：A = {x1/A(x1), x2/A(x2),..., xn/A(xn)}，其中xi∈U，A(xi)∈[0,1]。
     - **形式2**：A = ∫U A(x)/dx，其中∫表示积分符号。

   - **例子**：设论域U = {x1 (140), x2 (150), x3 (160), x4 (170), x5 (180), x6 (190)}(单位：cm) 表示人的身高，那么U上的一个模糊集“高个子”(A)的隶属函数A(x)可定义为：A(x) = {0.2/140, 0.4/150, 0.6/160, 0.8/170, 1/180, 1/190}。

   - 特点

     ：

     - **模糊性**：集合界限模糊，元素的隶属程度不是绝对的0或1，而是介于0和1之间。
     - **主观性**：隶属函数的确定方法是主观的，不同的人可能会给出不同的隶属函数。

2. 模糊集合运算

   ：

   - **相等**：设有两个模糊集合A和B，A=B当且仅当它们的隶属函数在论域U上恒等，即A(x) = B(x)，∀x∈U。
   - **包含**：A包含于B当且仅当对于论域U上的任意元素x，都有A(x) ≤ B(x)。
   - **并**：A∪B = {x/A(x)∨B(x)}，其中∨表示取最大值。
   - **交**：A∩B = {x/A(x)∧B(x)}，其中∧表示取最小值。
   - **补集**：Ā = {x/1 - A(x)}。
   - **积**：A×B = {x/A(x)×B(x)}。

3. 模糊关系

   ：

   - **定义**：设U、V是论域，从U到V上的模糊关系R是指U×V上的一个模糊集合，由隶属函数R(x,y)表示(x,y)之间的关系。
   - **表示**：当论域U、V是有限集时，模糊关系R常常采用矩阵来表示，此时它又称为模糊关系矩阵。
   - **模糊关系矩阵的乘法（合成）**：设R是U×V上的模糊关系矩阵，S是V×W上的模糊关系矩阵，则U×W上的模糊关系矩阵T：T = R×S，其中×表示模糊关系矩阵的乘法。

## 二、模糊假言推理

1. 模糊知识表示

   ：

   - **一般表示形式**：IF x is A THEN y is B(CF,λ)，其中A和B是模糊集合，CF是知识的可信度因子，λ表示阈值。

   - 规则的各种形式

     ：

     - **IF x is A THEN y is B(CF,λ)**
     - **IF x is A THEN y is B(CF)**
     - **IF x is A THEN y is B(λ)**
     - **IF x is A THEN y is B**

2. 前提的模糊匹配

   ：

   - **定义**：在模糊推理中，知识的前提条件中的A与证据中的A’不一定完全相同，因此在推理时，需要找到与证据A’能够匹配的知识前提A。

   - **匹配的方法**：计算A’和A的贴近度是否大于预先设定的阈值。

   - 贴近度的计算

     ：贴近度是用来衡量两个模糊集合之间的相似程度的指标，常用的贴近度计算方法有：

     - **最大最小贴近度**：D(A,B) = max(min(A(x),B(x)))。
     - **算术平均贴近度**：D(A,B) = (1/n)∑(A(x) + B(x))。
     - **几何平均贴近度**：D(A,B) = (1/n)∑(A(x)×B(x))^(1/2)。

3. 简单模糊推理

   ：

   - 推理方法及步骤

     ：

     - **首先计算A和B之间的模糊关系R**：R = A×B。
     - **通过R与前提的合成求出结论**：如果已知证据是A’，且A’和A的贴近度大于阈值λ，则有结论B’：B’ = A’×R。

   - **计算R**：Zadeh提出两种方法计算R，分别是极大极小原则计算Rm和算数原则计算Ra。

## 三、模糊决策

1. **模糊决策**：由模糊推理得到的结论或者操作是一个模糊向量，转化为确定值的过程。

2. 模糊决策的方法

   ：

   - **最大隶属度法**：取结论中隶属度最大的元素作为决策结果。
   - **加权平均判决法**：根据结论中各元素的隶属度和权重，计算加权平均值作为决策结果。
   - **中位数法**：取结论中隶属度大于等于0.5的元素的中位数作为决策结果。

## 四、模糊推理的应用

1. **模糊控制**：模糊控制是一种基于模糊逻辑的控制方法，它将模糊推理应用于控制系统中，实现对复杂系统的控制。
2. **模糊聚类分析**：模糊聚类分析是一种基于模糊逻辑的聚类方法，它将模糊推理应用于聚类分析中，实现对数据的模糊聚类。
3. **模糊模式识别**：模糊模式识别是一种基于模糊逻辑的模式识别方法，它将模糊推理应用于模式识别中，实现对模糊模式的识别。

# 5.非单调推理

缺省理论及其分类、表示形式，TMS系统原理

## 一、缺省理论

1. 缺省推理的形式定义

   ：令x为某个证据，y为默认x为真时的某结论，则缺省推理包含以下3种情形：

   - 定义1：若不知道x为假，则有结论y。
   - 定义2：若不能证明x为假，则有结论y。
   - 定义3：若不能在某个给定的时间期限内证明x为假，则有结论y。

2. 缺省规则的形式

   ：令A(x)为先决条件，Bi(x)为默认条件，C(x)为结论，M为模态算子，表示无法证明…为假或假定…是正确的，则缺省规则可表示为：

   - 规范缺省：默认条件与结论相同，由先决条件可以直接推理出结论。
   - 半规范缺省：默认条件与结论不同，由先决条件和默认条件可以推理出结论。
   - 不规范缺省：默认条件与结论不同，由先决条件、默认条件和其他条件可以推理出结论。

3. **缺省规则的推理思想**：非假即真；不是假的就认为是真的。

## 二、TMS系统原理

1. **TMS的原理**：TMS在程序所产生的各个命题中，保持命题间的相容性。一旦发现命题出现不相容（矛盾），TMS就调用推理机制，回溯找到不相容的根源，修正由这一根源以前推理得到的所有命题，从而消除不相容，维持系统的正确性。

2. TMS的工作过程

   ：当TMS遇到一个矛盾节点为IN，则唤醒面向从属关系的回溯，找出并删除当前的一个假设，即让该假设的状态为OUT，从而使得矛盾节点为OUT。

   - 步骤1：从矛盾节点开始，寻找它的基础节点，设为A1,A2, …,An，一般都放在矛盾节点的IN表中。
   - 步骤2：从A1开始，令此节点状态为OUT。
   - 步骤3：进行正确性维持检查，如果无法维持所有节点的IN/OUT状态，则撤销A1，取出下一个节点A2,　返回步骤2。
   - 如果A1,A2, …,An的任何一个或多个为OUT都无法维持所有节点的IN/OUT状态，则说明这是一个不可解决的矛盾。

# 6.主观Bayes推理

LS和LN的讨论、证据确定时的推理计算、证据不确定时的推理计算

## 一、LS和LN的讨论

1. **LS**：表示证据E的存在，影响结论R为真的概率。
2. **LN**：表示证据E的不存在，影响结论R为真的概率。
3. **LS和LN的取值范围**：LS和LN的取值范围都是[0,∞)。
4. **LS和LN的关系**：LS和LN是相互独立的，它们的取值不会相互影响。
5. **LS和LN的作用**：LS和LN可以用来描述证据E和结论R之间的关系，从而帮助我们更好地理解和分析问题。

## 二、证据确定时的推理计算

1. **证据E肯定存在**：根据公式5，P(R|E)=LS×P(R)/(LS-1)×P(R)+1。
2. **证据E肯定不存在**：根据公式6，P(R|﹁E)=LN×P(R)/(LN-1)×P(R)+1。

## 三、证据不确定时的推理计算

1. **杜达公式**：P(R|S)=P(R|E)×P(E|S)+P(R|﹁E)×P(﹁E|S)。
2. **分段线形插值**：当P(E|S)为其它值（非0，非1，非P(E)）时，则需要通过分段线形插值计算。

# 7.机器学习

机器学习模型、决策树学习的计算（熵、最佳属性、决策树画图）、ID3算法，概念学习的相关计算（实例空间和假设空间的计算、FIND-S算法）

## 一、机器学习模型

1. **定义**：如果一个计算机程序针对某类任务T，用P衡量性能，根据经验E来自我完善，那么就称该程序在从经验E中学习，针对任务T，它的性能用P来衡量。

2. 组成部分

   ：

   - **实例集合X**：与任务T相关的所有知识和解决问题的方法，可以包括正例和反例。
   - **假设集合H**：学习系统的学习结果的集合，表示方法包括属性表、规则、决策树等。
   - **训练样例集合D**：从实例集合中选出，用于训练学习系统进行学习的样例集合。
   - **目标函数C(x)**：是一个理想函数，参数x来自实例集合，取值为{0,1}。
   - **学习过程**：是一个在假设集合H中进行搜索的过程，学习过程使得搜索到的假设在训练样例集上与C(x)一致。
   - **机器学习假设**：学习系统学习到的假设，如果在D上逼近目标函数C(x)，那么也能在X-D上逼近目标函数C(x)。

## 二、决策树学习的计算

1. **熵**：系统混乱程度的度量，用于衡量某一个属性分类训练数据的能力。
2. **最佳属性选择**：信息增益，用于衡量某一个属性分类训练数据的能力，一个属性A相对训练样例集合S的信息增益Gain(S,A)表示根据属性A分类而导致S的熵的减小值。
3. **决策树画图**：根据决策树的结构，将实例从根节点开始，最后排列到某个叶节点来进行分类，叶节点就是实例所属的类别。

## 三、ID3算法

1. **基本思想**：通过自顶向下构造决策树进行学习，构造过程是从“哪一个属性将在树的根节点被测试”这个问题开始。

2. 算法步骤

   ：

   - 从训练样例集合中推导出决策树，使树生长直到尽可能好地拟合训练数据，允许过度拟合发生。
   - 将决策树转化为等价的规则集合，方法是对于从根节点到叶节点的每一条路径，创建一条规则。
   - 通过删除任何能导致估计精度提高的前件，来修剪每一条规则。
   - 按照修剪过的规则的估计精度，对它们进行排序，并按照该顺序，应用这些规则分类后来的实例。

## 四、概念学习的相关计算

1. 实例空间和假设空间的计算

   ：

   - **实例空间的大小**：实例空间的大小等于属性个数的幂次方。
   - **假设空间的大小**：假设空间的大小等于属性个数的幂次方乘以2的属性个数次方。

2. **FIND-S算法**：利用偏序关系，搜索一个特殊的假设，使得对于每个训练样例，当其为正例时，该假设将其判为正例；当其为反例时，该假设将其判为反例。

# 8.遗传算法

  遗传算法及其涉及的基本概念，了解算法步骤

## 一、遗传算法

1. **定义**：遗传算法是一种基于模拟进化的学习方法，它通过模拟生物进化的过程来搜索最优解。
2. **基本思想**：遗传算法从一个初始种群开始，通过选择、交叉和变异等操作，不断地进化种群，直到找到最优解或满足终止条件。
3. **应用领域**：遗传算法在机器学习、聚类、控制、规划、设计、调度、配置、组合优化、函数的最大值等领域得到了广泛的应用。

## 二、遗传算法涉及的基本概念

1. **个体**：个体是模拟生物个体，对问题中的对象（一般就是问题的解）的一种称呼，一个个个体也就是解空间中的一个点。
2. **种群**：种群是模拟生物种群，由若干个体组成的群体，它一般是整个解空间的一个很小的子集。
3. **适应度**：适应度就是借鉴生物个体对环境的适应程度，而对问题中的个体对象所设计的表征其优劣的一种测度。
4. **适应度函数**：适应度函数就是问题中的全体个体与其适应度之间的一个对应关系。它一般是一个实值函数。该函数就是遗传算法中指导搜索的评价函数，需要有效反映任一个染色体和最优解染色体的差距。
5. **染色体**：染色体就是问题中个体的某种字符串形式的编码表示。字符串中的字符也就称为基因（gene），即染色体上的任一位。
6. **基因**：基因是染色体上的基本单位，它决定了染色体的特征和表现形式。
7. **遗传操作**：遗传操作是指对染色体进行的操作，包括选择、交叉和变异等。
8. **选择**：选择是指从种群中选择适应度较高的个体，使其有更多的机会参与繁殖和进化。
9. **交叉**：交叉是指将两个染色体的部分基因进行交换，从而产生新的染色体。
10. **变异**：变异是指对染色体的某些基因进行随机改变，从而产生新的染色体。

## 三、遗传算法的步骤

1. **初始化种群**：随机生成一个初始种群，每个个体都是问题的一个潜在解。
2. **计算适应度**：计算每个个体的适应度，适应度是衡量个体优劣的指标。
3. **选择**：根据个体的适应度，选择适应度较高的个体作为父代，参与繁殖和进化。
4. **交叉**：对选择出的父代进行交叉操作，产生新的子代。
5. **变异**：对子代进行变异操作，增加种群的多样性。
6. **更新种群**：将新产生的子代加入种群中，替换掉适应度较低的个体。
7. **判断终止条件**：判断是否满足终止条件，如达到最大迭代次数或找到最优解。
8. **输出结果**：如果满足终止条件，输出最优解；否则，返回步骤2，继续进行进化。

# 9.神经网络

  人工神经网络定义及分类、生物神经元组成部分、多层神经网络、二输入感知器的判断与设计（画图）、三输入感知器的判断与设计（画图），BP网络及其学习算法、Hopfield网络分类、卷积神经网络、深度学习模型的分类、GAN对抗训练机制及其问题等

## 一、人工神经网络定义及分类

1. **定义**：人工神经网络是由具有适应性的简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的交互反应。

2. 分类

   ：

   - **相互连接网络**：包括单层网络、多层前向网络、带侧抑制的多层网络和带反馈的多层网络。
   - **分层网络**：包括单层网络、两层网络结构和多层网络结构。

## 二、生物神经元组成部分

1. **细胞体**：用于处理从其他神经元传递过来的信息。
2. **树突**：神经元的输入端。
3. **轴突**：相当于神经元的输出电缆，利用尾部的神经末梢和梢端的突触输出。
4. **突触**：神经元之间相互连接的接口，即一个神经元的神经末梢与另一个神经元的树突相接触的交接面。

## 三、多层神经网络

1. **定义**：3层及3层以上的神经网络，称多层神经网络。

2. 按照各层功能可分为

   ：

   - **输入层**：接收外部输入信号。
   - **中间层（隐层）**：可包含多层，对输入信号进行处理和转换。
   - **输出层**：输出网络的处理结果。

## 四、二输入感知器的判断与设计（画图）

1. **判断**：只要能画出一条直线，将输入点按照要求分成两类，那么就可以设计出相应的感知器，实现该功能。

2. 设计步骤

   ：

   - 画出布尔函数的真值表。
   - 画出x1--x2坐标系的输入点。
   - 画出对输入点正确分类的直线，标出正方向。
   - 写出直线方程。
   - 得到感知器的参数。

## 五、三输入感知器的判断与设计（画图）

1. **判断**：三输入感知器的权值表达式为：，其中为偏置项，为权重。感知器可以看成n维实例空间中的超平面决策面，对于该平面一侧的实例，感知器输出1，对于另一侧的实例输出0；正反例的集合，不一定能被超平面所分割；可以被超平面分割的集合称为线性可分的样例集合。

2. 设计步骤

   ：

   - 画出布尔函数的真值表。
   - 画出x1--x2--x3坐标系的输入点。
   - 画出对输入点正确分类的平面，标出正方向。
   - 写出平面方程。
   - 得到感知器的参数。

## 六、BP网络及其学习算法

1. **BP网络**：BP网络是一种多层前向神经网络，它的特点是信号前向传播，误差反向传播。BP网络的训练过程是通过不断调整网络的权重和阈值，使得网络的输出尽可能地接近目标输出。
2. **学习算法**：BP网络的学习算法是一种基于梯度下降的算法，它的基本思想是通过计算网络的输出误差，然后根据误差的大小来调整网络的权重和阈值，使得网络的输出误差逐渐减小。BP网络的学习算法包括正向传播和反向传播两个过程。

## 七、Hopfield网络分类

1. **离散型的霍普菲尔德网络（DHNN）**：激活函数为二值型的，其输入、输出为{0，1}的反馈网络，主要用于联想记忆。
2. **连续型的霍普菲尔德网络（CHNN）**：激活函数的输入与输出之间的关系为连续可微的单调上升函数，主要用于优化计算。

## 八、卷积神经网络

1. **卷积神经网络（CNN）**：是一种深度学习模型，它的特点是具有局部连接、权值共享和多卷积核等特点。CNN可以自动从图像中提取特征，并且可以处理高维数据，因此在图像识别、语音识别等领域得到了广泛的应用。

2. **卷积运算**：卷积运算是CNN的核心运算，它通过对输入数据进行卷积操作，来提取数据的特征。卷积运算的公式为：，其中为输入数据，为卷积核，为偏置项，为激活函数。

3. 关键技术

   ：

   - **局部链接**：CNN中的神经元只与输入数据的局部区域进行连接，而不是与整个输入数据进行连接。这种局部连接的方式可以减少网络的参数数量，提高网络的训练效率。
   - **权值共享**：CNN中的卷积核在不同的位置上共享相同的权值，这种权值共享的方式可以减少网络的参数数量，提高网络的训练效率。
   - **多卷积核**：CNN中可以使用多个卷积核来提取不同的特征，这种多卷积核的方式可以提高网络的特征提取能力。
   - **池化**：池化是CNN中的一种重要技术，它可以减少网络的参数数量，提高网络的训练效率。池化的常用方法有平均池化和最大池化。

## 九、深度学习模型的分类

1. **判别式模型**：将一个高维的感官输入映射为一个类别标签。
2. **生成式模型**：把随机点变成与数据集相似的图片。

## 十、GAN对抗训练机制及其问题

1. **对抗训练机制**：GAN由生成器和判别器组成，生成器的任务是生成尽可能真实的样本，判别器的任务是判断输入的样本是真实的还是生成的。生成器和判别器通过不断地对抗训练，来提高各自的性能。

2. 问题

   ：

   - **训练过程难以收敛，经常出现震荡**：GAN的训练过程是一个非凸优化问题，因此容易陷入局部最优解，导致训练过程难以收敛，经常出现震荡。
   - **训练收敛，但是出现模式崩溃（model collapse）**：GAN的训练过程中，可能会出现模式崩溃的问题，即生成器生成的样本过于单一，缺乏多样性。
   - **训练收敛，但是GAN还会生成一些没有意义或者现实中不可能出现的图片**：GAN的训练过程中，可能会出现生成一些没有意义或者现实中不可能出现的图片的问题，这是由于GAN的训练过程是一个无监督学习过程，因此容易受到噪声的影响。